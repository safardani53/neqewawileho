<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Google White American Doctor and Press Images Was Google Hacked? | SnapBlog</title><meta name=generator content="Hugo 0.98.0"><meta name=description content="Social media users went wild when they realized that Googling &#34;white American doctor&#34; yields a different result than they were expecting. Over the weekend of Aug. 8, social media users came across what seemed to be a hack in the Google image search algorithm. It turns out that if you Google image search the phrase “white American doctor,” images of Black doctors show up as the result instead. 
Article continues below advertisement"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/normalize.css><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/cayman.css><link rel=apple-touch-icon sizes=180x180 href=./apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=./favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=./favicon-16x16.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body><section class=page-header><h1 class=project-name>SnapBlog</h1><h2 class=project-tagline></h2><nav><a href=./index.html class=btn>Blog</a>
<a href=./sitemap.xml class=btn>Sitemap</a>
<a href=./index.xml class=btn>RSS</a></nav></section><section class=main-content><h1>Google White American Doctor and Press Images Was Google Hacked?</h1><div><strong>Publish date: </strong>2024-06-24</div><p class="sc-dksuAk kpjVcu">Social media users went wild when they realized that Googling "white American doctor" yields a different result than they were expecting.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/www.distractify.com/data:image/webp;base64><p>Over the weekend of Aug. 8, social media users came across what seemed to be a <a href=#>hack in the Google image search algorithm</a>. It turns out that if you Google image&nbsp;search the phrase “white American doctor,” images of Black doctors show up as the result instead.&nbsp;</p><p>Article continues below advertisement</p><p>This led many social media users to ask whether the search giant had been hacked by activists, or whether it was a conspiracy manufactured by Google itself. Anyway, you don’t have to be an SEO-pro to figure out just why these particular images show up in the image search.&nbsp;</p><p>Keep scrolling to understand this phenomenon and the importance of phrasing and keywords when tagging your images.&nbsp;</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src><p>Article continues below advertisement</p><h2 data-header=true class="sc-WZYaI IusWG">Why does Googling “white American doctor” result in images of Black doctors?</h2><p>When Twitter user <a href=# rel="noopener noreferrer">@_TheProphecy</a> tweeted, “Lmaooo idk who hacked the google algorithm but I am crying…google ‘white American doctor’ & press images,” people were wondering whether there was a glitch in the search algorithm or if the search engine had been hacked. Responders to the tweet also pointed out similar results&nbsp;for practically any profession with the words “white American” in front of it, including the search for “portraits of European people.”&nbsp;</p><p>But while many were wondering whether the results were an indication of a skewed algorithm or even a hack, it turns out the results are only a reflection of the way users themselves input information online.</p><p>Last year, a similar conversation was sparked off by Twitter user <a href=# rel="noopener noreferrer">@JenniferMascia</a> who tweeted about a similar odd search result. Jennifer asked her followers, "So I do a @Google search for 'Boston's black neighborhoods' and the 1st result that pops up is a list of Boston's 'worst' neighborhoods. How does that happen?”&nbsp;</p><p>Article continues below advertisement</p><p>Google public liaison <a href=# rel="noopener noreferrer">Danny Sullivan</a> explained to Jennifer that "the [results] page was strong on the aspect of 'Boston neighborhoods' generally and likely seemed more list-like than other pages in the results, so got automatically picked as a featured snippet."&nbsp;</p><p>He also said that while the featured snippet system usually works as it should, it isn't perfect and reporting through Google's Feedback tool helps clear up these mistakes when they happen.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src><p>Article continues below advertisement</p><p>He continued to explain that “when people post images of white couples, they tend to say only ‘couples’ & not provide a race. But when there are mixed couples, then ‘white’ gets mentioned. Our image search depends [heavily on] words — so when we don’t get the words, this can happen.”&nbsp;</p><h2 data-header=true class="sc-WZYaI IusWG">So, is Google showing a bias that favors images of African-Americans?</h2><p>Basically, what Danny was saying is that Google is only a mirror for how users search for content and how web pages are written to respond to those search queries. It’s not Google or its algorithms that are biased, it’s the bias of people who don’t use the right words to describe images that are used in an article. That’s why it’s important to match words near images, including alt tags and captions, with the keywords that users are going to search for.</p><p>Article continues below advertisement</p><p><a href=# rel="noopener noreferrer">Search Engine Journal</a> conducted an investigation by analyzing the code of the images that were appearing at the top of the search for “white American doctors.” They found that the code of the web pages on which the images of African-American doctors appeared had the keywords “white American doctor” in their headings, in close proximity to the image.&nbsp;</p><figure class="sc-bYwzba cYmwOA"></figure><p>Article continues below advertisement</p><p>So, when you search the term on Google, the search engine mines the code of various web pages and if it finds the keywords within code that are physically close to the code for the image, the results would show those images.</p><p>All this ties into how search engines interpret and understand a user’s intent when writing SEO-friendly content. Search Engine Journal asks the pertinent question, “If people don’t generally refer to Caucasian doctors as white doctors, how would publishers refer to Caucasian doctors on web pages?”</p><p>Google can only reflect back how we use search engines and how we upload content and write web pages. So the next time you’re creating a web page, remember that text around your images will have a huge influence in the way the image is ranked in a search result.&nbsp;</p><p>Tag your images correctly, kids!</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7pbXSramam6Ses7p6wqikaKhfnLyws8ueZLCgmamybq3Mnqmim5GjeqW7wq2mqw%3D%3D</p><footer class=site-footer><span class=site-footer-credits>Made with <a href=https://gohugo.io/>Hugo</a>. © 2022. All rights reserved.</span></footer></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>